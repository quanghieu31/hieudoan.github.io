<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Home</title><link>https://quanghieu31.github.io/posts/</link><description>Recent content in Posts on Home</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 09 May 2024 12:00:00 +0000</lastBuildDate><atom:link href="https://quanghieu31.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Multilayer perceptron</title><link>https://quanghieu31.github.io/posts/mlp/</link><pubDate>Thu, 09 May 2024 12:00:00 +0000</pubDate><guid>https://quanghieu31.github.io/posts/mlp/</guid><description>Overview Link to heading Goal: Explain how multilayer perceptron model is trained. Mostly for me to understand the foundation.
Half of the battle is the configurations and notations:
Suppose we want to classify 25x25 images and have 10 output labels $(\textbf{y})$. The data for training are labeled and cleaned. There are $m$ instances in the data, 625 features, and 10 labels. The data can be represented as a $m \times 625$ matrix or tabular-type.</description></item><item><title>First few words</title><link>https://quanghieu31.github.io/posts/first/</link><pubDate>Mon, 19 Dec 2022 23:44:17 +0700</pubDate><guid>https://quanghieu31.github.io/posts/first/</guid><description>This is for Hieu in the future. Very nice working on your first web! After many weekend hours, you did it. It was thrilling learning experience. I am proud of you, please don&amp;rsquo;t be skeptical of yourself, even though I bet that you are right now haha. Anyhow, if you feel so, remember that everything is going to be daijoubu.
Many thanks to my bro (https://cryptsu.github.io/) who has helped me so much during the design and development.</description></item></channel></rss>